{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "Assignment5 kaggle-cifar10 V1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyIAxbah-a5k"
      },
      "source": [
        "The following additional libraries are needed to run this\n",
        "notebook. Note that running on Colab is experimental, please report a Github\n",
        "issue if you have any problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPLMYZssAHMr"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_w_hyFP-a5o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3b14d76-a454-4dec-f815-94bd7ddb86af"
      },
      "source": [
        "!pip install d2l==0.15.1\n",
        "!pip install -U mxnet-cu101==1.7.0\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: d2l==0.15.1 in /usr/local/lib/python3.6/dist-packages (0.15.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from d2l==0.15.1) (1.1.4)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from d2l==0.15.1) (1.0.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from d2l==0.15.1) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from d2l==0.15.1) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->d2l==0.15.1) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->d2l==0.15.1) (2018.9)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l==0.15.1) (4.7.7)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l==0.15.1) (5.3.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l==0.15.1) (4.10.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l==0.15.1) (5.2.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l==0.15.1) (7.5.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l==0.15.1) (5.6.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->d2l==0.15.1) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->d2l==0.15.1) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->d2l==0.15.1) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->d2l==0.15.1) (1.15.0)\n",
            "Requirement already satisfied: jupyter-client>=4.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l==0.15.1) (5.3.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l==0.15.1) (2.6.1)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l==0.15.1) (1.9.0)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l==0.15.1) (4.3.3)\n",
            "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l==0.15.1) (19.0.2)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l==0.15.1) (4.6.3)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l==0.15.1) (0.2.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l==0.15.1) (2.11.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l==0.15.1) (5.0.8)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l==0.15.1) (1.5.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l==0.15.1) (0.9.1)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l==0.15.1) (5.1.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->d2l==0.15.1) (5.5.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->d2l==0.15.1) (1.0.18)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->d2l==0.15.1) (3.5.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.15.1) (1.4.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.15.1) (0.6.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.15.1) (0.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.15.1) (0.4.4)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.15.1) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.15.1) (3.2.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets->qtconsole->jupyter->d2l==0.15.1) (4.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook->jupyter->d2l==0.15.1) (1.1.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->notebook->jupyter->d2l==0.15.1) (2.6.0)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.8.1->notebook->jupyter->d2l==0.15.1) (0.6.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.15.1) (0.8.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.15.1) (50.3.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.15.1) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.15.1) (4.8.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->d2l==0.15.1) (0.2.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter->d2l==0.15.1) (20.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter->d2l==0.15.1) (0.5.1)\n",
            "Requirement already up-to-date: mxnet-cu101==1.7.0 in /usr/local/lib/python3.6/dist-packages (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu101==1.7.0) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu101==1.7.0) (0.8.4)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu101==1.7.0) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101==1.7.0) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101==1.7.0) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101==1.7.0) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101==1.7.0) (2020.6.20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 0,
        "id": "fIysMy2S-a5v"
      },
      "source": [
        "# Image Classification (CIFAR-10) on Kaggle\n",
        ":label:`sec_kaggle_cifar10`\n",
        "\n",
        "So far, we have been using Gluon's `data` package to directly obtain image datasets in the tensor format. In practice, however, image datasets often exist in the format of image files. In this section, we will start with the original image files and organize, read, and convert the files to the tensor format step by step.\n",
        "\n",
        "We performed an experiment on the CIFAR-10 dataset in :numref:`sec_image_augmentation`.\n",
        "This is an important data\n",
        "set in the computer vision field. Now, we will apply the knowledge we learned in\n",
        "the previous sections in order to participate in the Kaggle competition, which\n",
        "addresses CIFAR-10 image classification problems. The competition's web address\n",
        "is\n",
        "\n",
        "> https://www.kaggle.com/c/cifar-10\n",
        "\n",
        ":numref:`fig_kaggle_cifar10` shows the information on the competition's webpage. In order to submit the results, please register an account on the Kaggle website first.\n",
        "\n",
        "![CIFAR-10 image classification competition webpage information. The dataset for the competition can be accessed by clicking the \"Data\" tab.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/kaggle-cifar10.png?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_kaggle_cifar10`\n",
        "\n",
        "First, import the packages or modules required for the competition.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 1,
        "tab": [
          "mxnet"
        ],
        "id": "ABtDUn-F-a5v"
      },
      "source": [
        "import collections\n",
        "from d2l import mxnet as d2l\n",
        "import math\n",
        "from mxnet import autograd, gluon, init, npx\n",
        "from mxnet.gluon import nn\n",
        "import os\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import time # For V2 fresh runtime, try removing this line and see if it still runs.\n",
        "from zipfile import ZipFile\n",
        "\n",
        "npx.set_np()"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 2,
        "id": "O2aIoSTN-a5-"
      },
      "source": [
        "## Obtaining and Organizing the Dataset\n",
        "\n",
        "The competition data is divided into a training set and testing set. The training set contains $50,000$ images. The testing set contains $300,000$ images, of which $10,000$ images are used for scoring, while the other $290,000$ non-scoring images are included to prevent the manual labeling of the testing set and the submission of labeling results. The image formats in both datasets are PNG, with heights and widths of 32 pixels and three color channels (RGB). The images cover $10$ categories: planes, cars, birds, cats, deer, dogs, frogs, horses, boats, and trucks. The upper-left corner of :numref:`fig_kaggle_cifar10` shows some images of planes, cars, and birds in the dataset.\n",
        "\n",
        "### Downloading the Dataset\n",
        "\n",
        "After logging in to Kaggle, we can click on the \"Data\" tab on the CIFAR-10 image classification competition webpage shown in :numref:`fig_kaggle_cifar10` and download the dataset by clicking the \"Download All\" button. After unzipping the downloaded file in `../data`, and unzipping `train.7z` and `test.7z` inside it, you will find the entire dataset in the following paths:\n",
        "\n",
        "* ../data/cifar-10/train/[1-50000].png\n",
        "* ../data/cifar-10/test/[1-300000].png\n",
        "* ../data/cifar-10/trainLabels.csv\n",
        "* ../data/cifar-10/sampleSubmission.csv\n",
        "\n",
        "Here folders `train` and `test` contain the training and testing images respectively, `trainLabels.csv` has labels for the training images, and `sample_submission.csv` is a sample of submission.\n",
        "\n",
        "To make it easier to get started, we provide a small-scale sample of the dataset: it contains the first $1000$ training images and $5$ random testing images.\n",
        "To use the full dataset of the Kaggle competition, you need to set the following `demo` variable to `False`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 3,
        "tab": [
          "mxnet"
        ],
        "id": "4BLqV4Qc-a5_"
      },
      "source": [
        "#@save\n",
        "d2l.DATA_HUB['cifar10_tiny'] = (d2l.DATA_URL + 'kaggle_cifar10_tiny.zip',\n",
        "                                '2068874e4b9a9f0fb07ebe0ad2b29754449ccacd')\n",
        "\n",
        "# If you use the full dataset downloaded for the Kaggle competition, set\n",
        "# `demo` to False\n",
        "# the demo is so small it doesn't learn with the baseline parameters\n",
        "demo = False\n",
        "\n",
        "if demo:\n",
        "    data_dir = d2l.download_extract('cifar10_tiny')\n",
        "else:\n",
        "    # data_dir = '/content/drive/MyDrive/ML Datasets/cifar-10/'\n",
        "    data_dir = '/content/train_valid_test/'"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGonsW-c4gMf"
      },
      "source": [
        "# with ZipFile('/content/train_valid_test.zip', 'r') as zip_obj:\n",
        "#   file_list = zip_obj.namelist()\n",
        "#   for filename in file_list:\n",
        "#     if not filename.split('/')[-1].startswith('.'):\n",
        "#       zip_obj.extract(filename)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 4,
        "id": "rhhWGJ1Z-a6C"
      },
      "source": [
        "### Organizing the Dataset\n",
        "\n",
        "We need to organize datasets to facilitate model training and testing. Let us first read the labels from the csv file. The following function returns a dictionary that maps the filename without extension to its label.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 5,
        "tab": [
          "mxnet"
        ],
        "id": "sX4iUn0X-a6D"
      },
      "source": [
        "#@save\n",
        "def read_csv_labels(fname):\n",
        "    \"\"\"Read fname to return a name to label dictionary.\"\"\"\n",
        "    with open(fname, 'r') as f:\n",
        "        # Skip the file header line (column name)\n",
        "        lines = f.readlines()[1:]\n",
        "    tokens = [l.rstrip().split(',') for l in lines]\n",
        "    return dict(((name, label) for name, label in tokens))\n",
        "\n",
        "# labels = read_csv_labels(os.path.join(data_dir, 'trainLabels.csv'))\n",
        "# print('# training examples:', len(labels))\n",
        "# print('# classes:', len(set(labels.values())))"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 6,
        "id": "FltnPeZH-a6F"
      },
      "source": [
        "Next, we define the `reorg_train_valid` function to segment the validation set from the original training set. The argument `valid_ratio` in this function is the ratio of the number of examples in the validation set to the number of examples in the original training set. In particular, let $n$ be the number of images of the class with the least examples, and $r$ be the ratio, then we will use $\\max(\\lfloor nr\\rfloor,1)$ images for each class as the validation set.  Let us use `valid_ratio=0.1` as an example. Since the original training set has $50,000$ images, there will be $45,000$ images used for training and stored in the path \"`train_valid_test/train`\" when tuning hyperparameters, while the other $5,000$ images will be stored as validation set in the path \"`train_valid_test/valid`\". After organizing the data, images of the same class will be placed under the same folder so that we can read them later.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 7,
        "tab": [
          "mxnet"
        ],
        "id": "RiR-GyP8-a6G"
      },
      "source": [
        "#@save\n",
        "def copyfile(filename, target_dir):\n",
        "    \"\"\"Copy a file into a target directory.\"\"\"\n",
        "    os.makedirs(target_dir, exist_ok=True)\n",
        "    shutil.copy(filename, target_dir)\n",
        "\n",
        "#@save\n",
        "def reorg_train_valid(data_dir, labels, valid_ratio):\n",
        "  # The number of examples of the class with the least examples in the\n",
        "  # training dataset\n",
        "  n = collections.Counter(labels.values()).most_common()[-1][1]\n",
        "  # The number of examples per class for the validation set\n",
        "  n_valid_per_label = max(1, math.floor(n * valid_ratio))\n",
        "  if not os.path.isdir(data_dir+'train_valid_test/train') and not os.path.isdir(data_dir+'train_valid_test/valid'):\n",
        "    label_count = {}\n",
        "    for train_filenumber in range(1, 50001):#os.listdir(os.path.join(data_dir, 'train')):\n",
        "      train_file = str(train_filenumber)+'.png'\n",
        "      label = labels[str(train_filenumber)]\n",
        "      fname = os.path.join(data_dir, 'train', train_file)\n",
        "      # Copy to train_valid_test/train_valid with a subfolder per class\n",
        "      copyfile(fname, os.path.join(data_dir, 'train_valid_test',\n",
        "                                    'train_valid', label))\n",
        "      if label not in label_count or label_count[label] < n_valid_per_label:\n",
        "        # Copy to train_valid_test/valid\n",
        "        copyfile(fname, os.path.join(data_dir, 'train_valid_test',\n",
        "                                      'valid', label))\n",
        "        label_count[label] = label_count.get(label, 0) + 1\n",
        "      else:\n",
        "        # Copy to train_valid_test/train\n",
        "        copyfile(fname, os.path.join(data_dir, 'train_valid_test',\n",
        "                                      'train', label))\n",
        "  return n_valid_per_label"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 8,
        "id": "p5RuisrZ-a6I"
      },
      "source": [
        "The `reorg_test` function below is used to organize the testing set to facilitate the reading during prediction.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 9,
        "tab": [
          "mxnet"
        ],
        "id": "IMFSt7fU-a6I"
      },
      "source": [
        "#@save\n",
        "def reorg_test(data_dir):\n",
        "  if not os.path.isdir(data_dir+'train_valid_test/test/'):\n",
        "    for test_file in os.listdir(os.path.join(data_dir, 'test')):\n",
        "      if test_file != \".DS_Store\":\n",
        "        copyfile(os.path.join(data_dir, 'test', test_file),\n",
        "                os.path.join(data_dir, 'train_valid_test', 'test',\n",
        "                              'unknown'))"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 10,
        "id": "RMXQ0uCd-a6K"
      },
      "source": [
        "Finally, we use a function to call the previously defined `read_csv_labels`, `reorg_train_valid`, and `reorg_test` functions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 11,
        "tab": [
          "mxnet"
        ],
        "id": "scEVxVN3-a6K"
      },
      "source": [
        "def reorg_cifar10_data(data_dir, valid_ratio):\n",
        "    labels = read_csv_labels(os.path.join(data_dir, 'trainLabels.csv'))\n",
        "    reorg_train_valid(data_dir, labels, valid_ratio)\n",
        "    # reorg_test(data_dir)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 12,
        "id": "I1ki7Rx2-a6L"
      },
      "source": [
        "We only set the batch size to $4$ for the demo dataset. During actual training and testing, the complete dataset of the Kaggle competition should be used and `batch_size` should be set to a larger integer, such as $128$. We use $10\\%$ of the training examples as the validation set for tuning hyperparameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 13,
        "tab": [
          "mxnet"
        ],
        "id": "f8_DtUqq-a6M"
      },
      "source": [
        "# Consider increasing batch size to 256 or 512, research common values\n",
        "batch_size = 4 if demo else 128\n",
        "# valid_ratio = 0.1\n",
        "# reorg_cifar10_data(data_dir, valid_ratio)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 14,
        "id": "jJxTQIyd-a6N"
      },
      "source": [
        "## Image Augmentation\n",
        "\n",
        "To cope with overfitting, we use image augmentation. For example, by adding `transforms.RandomFlipLeftRight()`, the images can be flipped at random. We can also perform normalization for the three RGB channels of color images using `transforms.Normalize()`. Below, we list some of these operations that you can choose to use or modify depending on requirements.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 15,
        "tab": [
          "mxnet"
        ],
        "id": "mX9ro_pS-a6O"
      },
      "source": [
        "transform_train = gluon.data.vision.transforms.Compose([\n",
        "    # Magnify the image to a square of 40 pixels in both height and width\n",
        "    gluon.data.vision.transforms.Resize(40),\n",
        "    # Randomly crop a square image of 40 pixels in both height and width to\n",
        "    # produce a small square of 0.64 to 1 times the area of the original\n",
        "    # image, and then shrink it to a square of 32 pixels in both height and\n",
        "    # width\n",
        "    gluon.data.vision.transforms.RandomResizedCrop(32, scale=(0.64, 1.0), ratio=(1.0, 1.0)),\n",
        "    gluon.data.vision.transforms.RandomFlipLeftRight(),\n",
        "    # gluon.data.vision.transforms.RandomColorJitter(brightness=0.25, contrast=0.2, saturation=0.3), # Added in V1\n",
        "    # gluon.data.vision.transforms.RandomLighting(0.5), # Added in V1\n",
        "    gluon.data.vision.transforms.ToTensor(),\n",
        "    # gluon.data.vision.transforms.RandomRotation((-20, 20), zoom_in=True),  # Added in V1\n",
        "    # Normalize each channel of the image\n",
        "    gluon.data.vision.transforms.Normalize([0.4914, 0.4822, 0.4465],\n",
        "                                           [0.2023, 0.1994, 0.2010])])"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 16,
        "id": "u2KZ1RdM-a6P"
      },
      "source": [
        "In order to ensure the certainty of the output during testing, we only perform normalization on the image.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 17,
        "tab": [
          "mxnet"
        ],
        "id": "NNw9qQdg-a6Q"
      },
      "source": [
        "transform_test = gluon.data.vision.transforms.Compose([\n",
        "    gluon.data.vision.transforms.ToTensor(),\n",
        "    gluon.data.vision.transforms.Normalize([0.4914, 0.4822, 0.4465],\n",
        "                                           [0.2023, 0.1994, 0.2010])])"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 18,
        "id": "YeeovnmU-a6R"
      },
      "source": [
        "## Reading the Dataset\n",
        "\n",
        "Next, we can create the `ImageFolderDataset` instance to read the organized dataset containing the original image files, where each example includes the image and label.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S65TP7eJ2iV4"
      },
      "source": [
        "train_valid_ds, test_ds = [\n",
        "    gluon.data.vision.ImageFolderDataset(\n",
        "        os.path.join(data_dir, folder))\n",
        "    for folder in ['train_valid', 'test']]"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 19,
        "tab": [
          "mxnet"
        ],
        "id": "cQgbRkkP-a6R"
      },
      "source": [
        "# train_ds, valid_ds, train_valid_ds, test_ds = [\n",
        "#     gluon.data.vision.ImageFolderDataset(\n",
        "#         os.path.join(data_dir, 'train_valid_test', folder))\n",
        "#     for folder in ['train', 'valid', 'train_valid', 'test']]"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 20,
        "id": "Vh3sxshr-a6S"
      },
      "source": [
        "We specify the defined image augmentation operation in `DataLoader`. During training, we only use the validation set to evaluate the model, so we need to ensure the certainty of the output. During prediction, we will train the model on the combined training set and validation set to make full use of all labelled data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OuMnA8C2yX5"
      },
      "source": [
        "train_valid_iter = gluon.data.DataLoader(\n",
        "    train_valid_ds.transform_first(transform_train), batch_size, shuffle=True, # Try shuffling the training data\n",
        "    last_batch='discard')\n",
        "\n",
        "test_iter = gluon.data.DataLoader(\n",
        "    test_ds.transform_first(transform_test), batch_size, shuffle=False,\n",
        "    last_batch='keep')"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 21,
        "tab": [
          "mxnet"
        ],
        "id": "hOfh0TA2-a6T"
      },
      "source": [
        "# train_iter, train_valid_iter = [gluon.data.DataLoader(\n",
        "#     dataset.transform_first(transform_train), batch_size, shuffle=True,\n",
        "#     last_batch='discard') for dataset in (train_ds, train_valid_ds)]\n",
        "\n",
        "# valid_iter = gluon.data.DataLoader(\n",
        "#     valid_ds.transform_first(transform_test), batch_size, shuffle=False,\n",
        "#     last_batch='discard')\n",
        "\n",
        "# test_iter = gluon.data.DataLoader(\n",
        "#     test_ds.transform_first(transform_test), batch_size, shuffle=False,\n",
        "#     last_batch='keep')"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 22,
        "id": "PYtSov7f-a6U"
      },
      "source": [
        "## Defining the Model\n",
        "\n",
        "Here, we build the residual blocks based on the `HybridBlock` class, which is\n",
        "slightly different than the implementation described in\n",
        ":numref:`sec_resnet`. This is done to improve execution efficiency.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 23,
        "tab": [
          "mxnet"
        ],
        "id": "Te6Fivlm-a6U"
      },
      "source": [
        "class Residual(nn.HybridBlock):\n",
        "    def __init__(self, num_channels, use_1x1conv=False, strides=1, **kwargs):\n",
        "        super(Residual, self).__init__(**kwargs)\n",
        "        self.conv1 = nn.Conv2D(num_channels, kernel_size=3, padding=1,\n",
        "                               strides=strides)\n",
        "        self.conv2 = nn.Conv2D(num_channels, kernel_size=3, padding=1)\n",
        "        if use_1x1conv:\n",
        "            self.conv3 = nn.Conv2D(num_channels, kernel_size=1,\n",
        "                                   strides=strides)\n",
        "        else:\n",
        "            self.conv3 = None\n",
        "        self.bn1 = nn.BatchNorm()\n",
        "        self.bn2 = nn.BatchNorm()\n",
        "\n",
        "    def hybrid_forward(self, F, X):\n",
        "        Y = F.npx.relu(self.bn1(self.conv1(X)))\n",
        "        Y = self.bn2(self.conv2(Y))\n",
        "        if self.conv3:\n",
        "            X = self.conv3(X)\n",
        "        return F.npx.relu(Y + X)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 24,
        "id": "43Q5t2IR-a6V"
      },
      "source": [
        "Next, we define the ResNet-18 model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 25,
        "tab": [
          "mxnet"
        ],
        "id": "3kc-1wpw-a6W"
      },
      "source": [
        "def resnet18(num_classes):\n",
        "    net = nn.HybridSequential()\n",
        "    # Consider changing initial filter count\n",
        "    net.add(nn.Conv2D(64, kernel_size=3, strides=1, padding=1),\n",
        "            nn.BatchNorm(), nn.Activation('relu'))\n",
        "\n",
        "    def resnet_block(num_channels, num_residuals, first_block=False):\n",
        "        blk = nn.HybridSequential()\n",
        "        for i in range(num_residuals):\n",
        "            if i == 0 and not first_block:\n",
        "                blk.add(Residual(num_channels, use_1x1conv=True, strides=2))\n",
        "            else:\n",
        "                blk.add(Residual(num_channels))\n",
        "        return blk\n",
        "\n",
        "    # Consider changing block structure\n",
        "    net.add(resnet_block(64, 2, first_block=True),\n",
        "            resnet_block(128, 2),\n",
        "            resnet_block(256, 2),\n",
        "            resnet_block(512, 2))\n",
        "    \n",
        "    net.add(nn.GlobalAvgPool2D(), nn.Dense(num_classes))\n",
        "    return net"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 26,
        "id": "XEspuiD7-a6X"
      },
      "source": [
        "The CIFAR-10 image classification challenge uses 10 categories. We will perform Xavier random initialization on the model before training begins.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 27,
        "tab": [
          "mxnet"
        ],
        "id": "bwsuwPcw-a6X"
      },
      "source": [
        "def get_net(devices):\n",
        "    num_classes = 10\n",
        "    net = resnet18(num_classes)\n",
        "    net.initialize(ctx=devices, init=init.Xavier())\n",
        "    return net\n",
        "\n",
        "loss = gluon.loss.SoftmaxCrossEntropyLoss()"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 28,
        "id": "oS0QY9jo-a6Y"
      },
      "source": [
        "## Defining the Training Functions\n",
        "\n",
        "We will select the model and tune hyperparameters according to the model's performance on the validation set. Next, we define the model training function `train`. We record the training time of each epoch, which helps us compare the time costs of different models.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 29,
        "tab": [
          "mxnet"
        ],
        "id": "MS3__W6y-a6Z"
      },
      "source": [
        "def train(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period,\n",
        "          lr_decay):\n",
        "    # Consider changing momentum (0.99?)\n",
        "    trainer = gluon.Trainer(net.collect_params(), 'sgd',\n",
        "                            {'learning_rate': lr, 'momentum': 0.9, 'wd': wd})\n",
        "    num_batches, timer = len(train_iter), d2l.Timer()\n",
        "    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs],\n",
        "                            legend=['train loss', 'train acc', 'valid acc'])\n",
        "    for epoch in range(num_epochs):\n",
        "        metric = d2l.Accumulator(3)\n",
        "        if epoch > 0 and epoch % lr_period == 0:\n",
        "            trainer.set_learning_rate(trainer.learning_rate * lr_decay)\n",
        "        for i, (features, labels) in enumerate(train_iter):\n",
        "            timer.start()\n",
        "            l, acc = d2l.train_batch_ch13(\n",
        "                net, features, labels.astype('float32'), loss, trainer,\n",
        "                devices, d2l.split_batch)\n",
        "            metric.add(l, acc, labels.shape[0])\n",
        "            timer.stop()\n",
        "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
        "                animator.add(epoch + (i + 1) / num_batches,\n",
        "                             (metric[0] / metric[2], metric[1] / metric[2],\n",
        "                              None))\n",
        "        if valid_iter is not None:\n",
        "            valid_acc = d2l.evaluate_accuracy_gpus(net, valid_iter,\n",
        "                                                   d2l.split_batch)\n",
        "            animator.add(epoch + 1, (None, None, valid_acc))\n",
        "    if valid_iter is not None:\n",
        "        print(f'loss {metric[0] / metric[2]:.3f}, '\n",
        "              f'train acc {metric[1] / metric[2]:.3f}, '\n",
        "              f'valid acc {valid_acc:.3f}')\n",
        "    else:\n",
        "        print(f'loss {metric[0] / metric[2]:.3f}, '\n",
        "              f'train acc {metric[1] / metric[2]:.3f}')\n",
        "    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '\n",
        "          f'on {str(devices)}')"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 30,
        "id": "agrZio6j-a6a"
      },
      "source": [
        "## Training and Validating the Model\n",
        "\n",
        "Now, we can train and validate the model. The following hyperparameters can be tuned. For example, we can increase the number of epochs. Because `lr_period` and `lr_decay` are set to 50 and 0.1 respectively, the learning rate of the optimization algorithm will be multiplied by 0.1 after every 50 epochs. For simplicity, we only train one epoch here.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 31,
        "tab": [
          "mxnet"
        ],
        "id": "I8hsvTD1-a6a"
      },
      "source": [
        "# Consider altering learning rate\n",
        "# Epochs also could be higher, did not level off in baseline test\n",
        "# Research weight decay and learning rate decay\n",
        "devices, num_epochs, lr, wd = d2l.try_all_gpus(), 50, 0.1, 5e-4\n",
        "lr_period, lr_decay, net = 10, 0.2, get_net(devices)\n",
        "# net.hybridize()\n",
        "# train(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period,\n",
        "      # lr_decay)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 32,
        "id": "lshPf2Yz-a6c"
      },
      "source": [
        "## Classifying the Testing Set and Submitting Results on Kaggle\n",
        "\n",
        "After obtaining a satisfactory model design and hyperparameters, we use all training datasets (including validation sets) to retrain the model and classify the testing set.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Af47RM0_cOuY"
      },
      "source": [
        "transform_train = gluon.data.vision.transforms.Compose([\n",
        "    gluon.data.vision.transforms.Resize(40),\n",
        "    gluon.data.vision.transforms.RandomResizedCrop(32, scale=(0.64, 1.0), ratio=(1.0, 1.0)),\n",
        "    gluon.data.vision.transforms.RandomFlipLeftRight(),\n",
        "    gluon.data.vision.transforms.RandomColorJitter(brightness=0.3, contrast=0.2, saturation=0.1), # Added in V1\n",
        "    gluon.data.vision.transforms.RandomLighting(0.1), # Added in V1\n",
        "    gluon.data.vision.transforms.ToTensor(),\n",
        "    gluon.data.vision.transforms.Normalize([0.4914, 0.4822, 0.4465],\n",
        "                                           [0.2023, 0.1994, 0.2010])])\n",
        "\n",
        "train_valid_iter = gluon.data.DataLoader(\n",
        "    train_valid_ds.transform_first(transform_train), batch_size, shuffle=True, # Try shuffling the training data\n",
        "    last_batch='discard')"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 33,
        "tab": [
          "mxnet"
        ],
        "id": "-_eYPrRl-a6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "3dafb6c8-0b1a-4177-aee7-affc51cdd3f2"
      },
      "source": [
        "net, preds = get_net(devices), []\n",
        "net.hybridize()\n",
        "train(net, train_valid_iter, None, num_epochs, lr, wd, devices, lr_period,\n",
        "      lr_decay)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss 0.048, train acc 0.986\n",
            "1325.8 examples/sec on [gpu(0)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 252x180 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"180.65625pt\" version=\"1.1\" viewBox=\"0 0 229.425 180.65625\" width=\"229.425pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 180.65625 \nL 229.425 180.65625 \nL 229.425 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 20.5625 143.1 \nL 215.8625 143.1 \nL 215.8625 7.2 \nL 20.5625 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#pe338029c5a)\" d=\"M 56.433929 143.1 \nL 56.433929 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m031919b45f\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"56.433929\" xlink:href=\"#m031919b45f\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 10 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(50.071429 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#pe338029c5a)\" d=\"M 96.291071 143.1 \nL 96.291071 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"96.291071\" xlink:href=\"#m031919b45f\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 20 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(89.928571 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#pe338029c5a)\" d=\"M 136.148214 143.1 \nL 136.148214 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"136.148214\" xlink:href=\"#m031919b45f\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 30 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(129.785714 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#pe338029c5a)\" d=\"M 176.005357 143.1 \nL 176.005357 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"176.005357\" xlink:href=\"#m031919b45f\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 40 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(169.642857 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#pe338029c5a)\" d=\"M 215.8625 143.1 \nL 215.8625 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"215.8625\" xlink:href=\"#m031919b45f\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 50 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(209.5 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_6\">\n     <!-- epoch -->\n     <defs>\n      <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n      <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n      <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n      <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-104\"/>\n     </defs>\n     <g transform=\"translate(102.984375 171.376563)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"61.523438\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"125\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"186.181641\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"241.162109\" xlink:href=\"#DejaVuSans-104\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#pe338029c5a)\" d=\"M 20.5625 137.803723 \nL 215.8625 137.803723 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m70bf3d279b\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m70bf3d279b\" y=\"137.803723\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0 -->\n      <g transform=\"translate(7.2 141.602942)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_13\">\n      <path clip-path=\"url(#pe338029c5a)\" d=\"M 20.5625 98.153632 \nL 215.8625 98.153632 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m70bf3d279b\" y=\"98.153632\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 2 -->\n      <g transform=\"translate(7.2 101.952851)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_15\">\n      <path clip-path=\"url(#pe338029c5a)\" d=\"M 20.5625 58.503542 \nL 215.8625 58.503542 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m70bf3d279b\" y=\"58.503542\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 4 -->\n      <g transform=\"translate(7.2 62.30276)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_17\">\n      <path clip-path=\"url(#pe338029c5a)\" d=\"M 20.5625 18.853451 \nL 215.8625 18.853451 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m70bf3d279b\" y=\"18.853451\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 6 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(7.2 22.65267)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_19\">\n    <path clip-path=\"url(#pe338029c5a)\" d=\"M 17.373929 13.377273 \nL 18.171071 50.273855 \nL 18.968214 62.173263 \nL 19.765357 69.70347 \nL 20.5625 74.379492 \nL 21.359643 95.621114 \nL 22.156786 96.678238 \nL 24.548214 99.154307 \nL 25.345357 103.580154 \nL 26.1425 104.289753 \nL 26.939643 104.68025 \nL 28.533929 105.702591 \nL 29.331071 108.461704 \nL 31.7225 109.785517 \nL 32.519643 110.291503 \nL 33.316786 112.862785 \nL 34.113929 113.293557 \nL 34.911071 113.899382 \nL 36.505357 114.700972 \nL 37.3025 117.816981 \nL 39.693929 118.782338 \nL 40.491071 119.114893 \nL 41.288214 120.903715 \nL 42.085357 121.105958 \nL 42.8825 121.464183 \nL 44.476786 121.769958 \nL 45.273929 123.22664 \nL 46.071071 123.032536 \nL 46.868214 123.256218 \nL 48.4625 123.375405 \nL 49.259643 124.130796 \nL 50.056786 124.063032 \nL 52.448214 124.283049 \nL 53.245357 124.752731 \nL 54.0425 125.03072 \nL 55.636786 125.03019 \nL 56.433929 125.009659 \nL 57.231071 126.810033 \nL 58.028214 127.716757 \nL 58.825357 128.13218 \nL 60.419643 128.632087 \nL 61.216786 129.793952 \nL 62.811071 129.900405 \nL 64.405357 129.981648 \nL 65.2025 130.365866 \nL 67.593929 130.492937 \nL 68.391071 130.468474 \nL 69.188214 131.061807 \nL 72.376786 130.953319 \nL 73.173929 131.75931 \nL 75.565357 131.448775 \nL 76.3625 131.388698 \nL 77.159643 132.006387 \nL 79.551071 131.549813 \nL 80.348214 131.546878 \nL 81.145357 132.096829 \nL 81.9425 132.109807 \nL 83.536786 131.955419 \nL 84.333929 131.877712 \nL 85.131071 132.514344 \nL 86.725357 132.275925 \nL 88.319643 132.077239 \nL 89.116786 132.484033 \nL 91.508214 132.207075 \nL 92.305357 132.111388 \nL 93.1025 132.742308 \nL 96.291071 132.449578 \nL 97.088214 133.326092 \nL 97.885357 133.666368 \nL 99.479643 133.870503 \nL 100.276786 133.973262 \nL 101.073929 134.627103 \nL 105.059643 134.78027 \nL 106.653929 134.880511 \nL 108.248214 134.899643 \nL 109.045357 135.259856 \nL 110.639643 135.301281 \nL 112.233929 135.291902 \nL 113.828214 135.474844 \nL 116.219643 135.395809 \nL 117.016786 135.685549 \nL 118.611071 135.62887 \nL 120.205357 135.550637 \nL 121.0025 135.784026 \nL 121.799643 135.82918 \nL 124.191071 135.727879 \nL 125.785357 135.884167 \nL 128.176786 135.830332 \nL 128.973929 136.053763 \nL 132.1625 135.925444 \nL 132.959643 136.122683 \nL 133.756786 135.984084 \nL 136.148214 135.962073 \nL 136.945357 136.199559 \nL 140.133929 136.321611 \nL 140.931071 136.431788 \nL 141.728214 136.350067 \nL 144.119643 136.430094 \nL 151.293929 136.50397 \nL 152.091071 136.504695 \nL 153.685357 136.67612 \nL 157.671071 136.644552 \nL 159.265357 136.664442 \nL 165.6425 136.639976 \nL 167.236786 136.700048 \nL 172.019643 136.674529 \nL 174.411071 136.7793 \nL 215.8625 136.852211 \nL 215.8625 136.852211 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_20\">\n    <path clip-path=\"url(#pe338029c5a)\" d=\"M 17.373929 135.784285 \nL 18.968214 135.818703 \nL 20.5625 135.64767 \nL 21.359643 134.070641 \nL 22.156786 133.500751 \nL 24.548214 132.360175 \nL 25.345357 130.5262 \nL 26.1425 130.25714 \nL 28.533929 129.737884 \nL 29.331071 128.83837 \nL 32.519643 128.029801 \nL 33.316786 126.953958 \nL 36.505357 126.231567 \nL 37.3025 124.996076 \nL 39.693929 124.669928 \nL 40.491071 124.548504 \nL 41.288214 123.907923 \nL 43.679643 123.628935 \nL 44.476786 123.598554 \nL 45.273929 123.050108 \nL 46.071071 123.1206 \nL 55.636786 122.40774 \nL 56.433929 122.396819 \nL 57.231071 121.709773 \nL 58.028214 121.409935 \nL 59.6225 121.209878 \nL 60.419643 121.125983 \nL 61.216786 120.699061 \nL 63.608214 120.686154 \nL 68.391071 120.530278 \nL 69.188214 120.24434 \nL 71.579643 120.311853 \nL 72.376786 120.340844 \nL 73.173929 120.073572 \nL 76.3625 120.225675 \nL 77.159643 119.948474 \nL 79.551071 120.134631 \nL 80.348214 120.14029 \nL 81.145357 119.900817 \nL 83.536786 119.967338 \nL 84.333929 120.016384 \nL 85.131071 119.74792 \nL 88.319643 119.950062 \nL 89.116786 119.819404 \nL 92.305357 119.963168 \nL 93.1025 119.745934 \nL 96.291071 119.822184 \nL 97.088214 119.477867 \nL 99.479643 119.313552 \nL 100.276786 119.268179 \nL 101.073929 119.003289 \nL 105.059643 118.989389 \nL 113.828214 118.737208 \nL 116.219643 118.766993 \nL 117.016786 118.631967 \nL 121.0025 118.651824 \nL 126.5825 118.609462 \nL 128.176786 118.622435 \nL 129.771071 118.522754 \nL 132.1625 118.585502 \nL 132.959643 118.492969 \nL 134.553929 118.553201 \nL 136.945357 118.494955 \nL 180.788214 118.266601 \nL 188.759643 118.284472 \nL 195.136786 118.28199 \nL 208.688214 118.264616 \nL 215.8625 118.249922 \nL 215.8625 118.249922 \n\" style=\"fill:none;stroke:#bf00bf;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_21\"/>\n   <g id=\"patch_3\">\n    <path d=\"M 20.5625 143.1 \nL 20.5625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 215.8625 143.1 \nL 215.8625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 20.5625 143.1 \nL 215.8625 143.1 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 20.5625 7.2 \nL 215.8625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 131.09375 59.234375 \nL 208.8625 59.234375 \nQ 210.8625 59.234375 210.8625 57.234375 \nL 210.8625 14.2 \nQ 210.8625 12.2 208.8625 12.2 \nL 131.09375 12.2 \nQ 129.09375 12.2 129.09375 14.2 \nL 129.09375 57.234375 \nQ 129.09375 59.234375 131.09375 59.234375 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_22\">\n     <path d=\"M 133.09375 20.298438 \nL 153.09375 20.298438 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_23\"/>\n    <g id=\"text_11\">\n     <!-- train loss -->\n     <defs>\n      <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n      <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n      <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n      <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n      <path id=\"DejaVuSans-32\"/>\n      <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n      <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n     </defs>\n     <g transform=\"translate(161.09375 23.798438)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"232.763672\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"264.550781\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"292.333984\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"353.515625\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"405.615234\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n    <g id=\"line2d_24\">\n     <path d=\"M 133.09375 34.976562 \nL 153.09375 34.976562 \n\" style=\"fill:none;stroke:#bf00bf;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_25\"/>\n    <g id=\"text_12\">\n     <!-- train acc -->\n     <g transform=\"translate(161.09375 38.476562)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"232.763672\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"264.550781\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"325.830078\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"380.810547\" xlink:href=\"#DejaVuSans-99\"/>\n     </g>\n    </g>\n    <g id=\"line2d_26\">\n     <path d=\"M 133.09375 49.654688 \nL 153.09375 49.654688 \n\" style=\"fill:none;stroke:#008000;stroke-dasharray:9.6,2.4,1.5,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_27\"/>\n    <g id=\"text_13\">\n     <!-- valid acc -->\n     <defs>\n      <path d=\"M 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 8.796875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nL 35.6875 0 \nL 23.484375 0 \nz\n\" id=\"DejaVuSans-118\"/>\n      <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n     </defs>\n     <g transform=\"translate(161.09375 53.154688)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-118\"/>\n      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"148.242188\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"176.025391\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"239.501953\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"271.289062\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"332.568359\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"387.548828\" xlink:href=\"#DejaVuSans-99\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pe338029c5a\">\n   <rect height=\"135.9\" width=\"195.3\" x=\"20.5625\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55N4IRuqXrhY"
      },
      "source": [
        "for X, _ in test_iter:\n",
        "    y_hat = net(X.as_in_ctx(devices[0]))\n",
        "    preds.extend(y_hat.argmax(axis=1).astype(int).asnumpy())\n",
        "sorted_ids = list(range(1, len(test_ds) + 1))\n",
        "sorted_ids.sort(key=lambda x: str(x))\n",
        "df = pd.DataFrame({'id': sorted_ids, 'label': preds})\n",
        "df['label'] = df['label'].apply(lambda x: train_valid_ds.synsets[x])\n",
        "df.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 34,
        "id": "T2CCZo1F-a6e"
      },
      "source": [
        "After executing the above code, we will get a \"submission.csv\" file. The format\n",
        "of this file is consistent with the Kaggle competition requirements. The method\n",
        "for submitting results is similar to method in :numref:`sec_kaggle_house`.\n",
        "\n",
        "## Summary\n",
        "\n",
        "* We can create an `ImageFolderDataset` instance to read the dataset containing the original image files.\n",
        "* We can use convolutional neural networks, image augmentation, and hybrid programming to take part in an image classification competition.\n",
        "\n",
        "\n",
        "## Exercises\n",
        "\n",
        "1. Use the complete CIFAR-10 dataset for the Kaggle competition. Change the `batch_size` and number of epochs `num_epochs` to 128 and 100, respectively.  See what accuracy and ranking you can achieve in this competition.\n",
        "1. What accuracy can you achieve when not using image augmentation?\n",
        "1. Scan the QR code to access the relevant discussions and exchange ideas about the methods used and the results obtained with the community. Can you come up with any better techniques?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 35,
        "tab": [
          "mxnet"
        ],
        "id": "4rdOOMy9-a6e"
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/379)\n"
      ]
    }
  ]
}