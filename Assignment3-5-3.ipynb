{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"colab":{"name":"Assignment3-5-3.ipynb","provenance":[{"file_id":"https://github.com/d2l-ai/d2l-pytorch-colab/blob/master/chapter_recurrent-neural-networks/rnn-scratch.ipynb","timestamp":1601822875540}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"dzj1q-AMFVKP"},"source":["The following additional libraries are needed to run this\n","notebook. Note that running on Colab is experimental, please report a Github\n","issue if you have any problem."]},{"cell_type":"code","metadata":{"id":"SsKOIMACFVKR","executionInfo":{"status":"ok","timestamp":1601842156448,"user_tz":240,"elapsed":2850,"user":{"displayName":"Spencer Hoffman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKsq1sDpOiHSP5_-g5HIG4jyq-Cm0H11FItTDA=s64","userId":"10955597740158350437"}},"outputId":"96d8b99b-23f2-4af3-d259-ff2649075955","colab":{"base_uri":"https://localhost:8080/","height":870}},"source":["!pip install d2l==0.14.4\n"],"execution_count":473,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: d2l==0.14.4 in /usr/local/lib/python3.6/dist-packages (0.14.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from d2l==0.14.4) (1.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from d2l==0.14.4) (1.18.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from d2l==0.14.4) (3.2.2)\n","Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from d2l==0.14.4) (1.0.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->d2l==0.14.4) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->d2l==0.14.4) (2018.9)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->d2l==0.14.4) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->d2l==0.14.4) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->d2l==0.14.4) (0.10.0)\n","Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l==0.14.4) (4.7.7)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l==0.14.4) (7.5.1)\n","Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l==0.14.4) (5.2.0)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l==0.14.4) (5.6.1)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l==0.14.4) (4.10.1)\n","Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l==0.14.4) (5.3.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->d2l==0.14.4) (1.15.0)\n","Requirement already satisfied: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l==0.14.4) (1.9.0)\n","Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l==0.14.4) (19.0.2)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l==0.14.4) (2.6.1)\n","Requirement already satisfied: jupyter-client>=4.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l==0.14.4) (5.3.5)\n","Requirement already satisfied: traitlets in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l==0.14.4) (4.3.3)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l==0.14.4) (4.6.3)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l==0.14.4) (0.2.0)\n","Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->d2l==0.14.4) (5.0.7)\n","Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->d2l==0.14.4) (5.5.0)\n","Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->d2l==0.14.4) (3.5.1)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->d2l==0.14.4) (1.0.18)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.14.4) (3.2.1)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.14.4) (0.4.4)\n","Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.14.4) (2.11.2)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.14.4) (1.4.2)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.14.4) (0.3)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.14.4) (0.8.4)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.14.4) (0.6.0)\n","Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->d2l==0.14.4) (5.1.1)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l==0.14.4) (1.5.0)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l==0.14.4) (0.9.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets->qtconsole->jupyter->d2l==0.14.4) (4.4.2)\n","Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->d2l==0.14.4) (2.6.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->d2l==0.14.4) (50.3.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->d2l==0.14.4) (0.7.5)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->d2l==0.14.4) (4.8.0)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->d2l==0.14.4) (0.8.1)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->d2l==0.14.4) (0.2.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter->d2l==0.14.4) (20.4)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter->d2l==0.14.4) (0.5.1)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert->jupyter->d2l==0.14.4) (1.1.1)\n","Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.8.1->notebook->jupyter->d2l==0.14.4) (0.6.0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"origin_pos":0,"id":"s-vng1CIFVKZ"},"source":["# Implementation of Recurrent Neural Networks from Scratch\n",":label:`sec_rnn_scratch`\n","\n","In this section we will implement an RNN\n","from scratch\n","for a character-level language model,\n","according to our descriptions\n","in :numref:`sec_rnn`.\n","Such a model\n","will be trained on H. G. Wells' *The Time Machine*.\n","As before, we start by reading the dataset first, which is introduced in :numref:`sec_language_model`.\n"]},{"cell_type":"code","metadata":{"origin_pos":2,"tab":["pytorch"],"id":"rD5GvkYtFVKa","executionInfo":{"status":"ok","timestamp":1601842156448,"user_tz":240,"elapsed":2839,"user":{"displayName":"Spencer Hoffman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKsq1sDpOiHSP5_-g5HIG4jyq-Cm0H11FItTDA=s64","userId":"10955597740158350437"}}},"source":["%matplotlib inline\n","from d2l import torch as d2l\n","import math\n","import torch\n","from torch import nn\n","from torch.nn import functional as F"],"execution_count":474,"outputs":[]},{"cell_type":"code","metadata":{"origin_pos":4,"tab":["pytorch"],"id":"1VjlMuTEFVKf","executionInfo":{"status":"ok","timestamp":1601842156449,"user_tz":240,"elapsed":2837,"user":{"displayName":"Spencer Hoffman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKsq1sDpOiHSP5_-g5HIG4jyq-Cm0H11FItTDA=s64","userId":"10955597740158350437"}}},"source":["batch_size, num_steps = 32, 35\n","train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)"],"execution_count":475,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":6,"id":"xWL7beroFVKj"},"source":["## One-Hot Encoding\n","\n","Recall that each token is represented as a numerical index in `train_iter`.\n","Feeding these indices directly to a neural network might make it hard to\n","learn.\n","We often represent each token as a more expressive feature vector.\n","The easiest representation is called *one-hot encoding*,\n","which is introduced\n","in :numref:`subsec_classification-problem`.\n","\n","In a nutshell, we map each index to a different unit vector: assume that the number of different tokens in the vocabulary is $N$ (`len(vocab)`) and the token indices range from 0 to $N-1$.\n","If the index of a token is the integer $i$, then we create a vector of all 0s with a length of $N$ and set the element at position $i$ to 1.\n","This vector is the one-hot vector of the original token. The one-hot vectors with indices 0 and 2 are shown below.\n"]},{"cell_type":"code","metadata":{"origin_pos":8,"tab":["pytorch"],"id":"bvqI0N3bFVKk","executionInfo":{"status":"ok","timestamp":1601842156449,"user_tz":240,"elapsed":2832,"user":{"displayName":"Spencer Hoffman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKsq1sDpOiHSP5_-g5HIG4jyq-Cm0H11FItTDA=s64","userId":"10955597740158350437"}},"outputId":"65068e8c-53d3-4b07-fcc3-7711f08227cb","colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["F.one_hot(torch.tensor([0, 2]), len(vocab))"],"execution_count":476,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0],\n","        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0]])"]},"metadata":{"tags":[]},"execution_count":476}]},{"cell_type":"markdown","metadata":{"origin_pos":10,"id":"D1sIIgiVFVKp"},"source":["The shape of the minibatch that we sample each time is (batch size, number of time steps).\n","The `one_hot` function transforms such a minibatch into a three-dimensional tensor with the last dimension equals to the vocabulary size (`len(vocab)`).\n","We often transpose the input so that we will obtain an\n","output of shape\n","(number of time steps, batch size, vocabulary size).\n","This will allow us\n","to more conveniently\n","loop through the outermost dimension\n","for updating hidden states of a minibatch,\n","time step by time step.\n"]},{"cell_type":"code","metadata":{"origin_pos":12,"tab":["pytorch"],"id":"sxobZnbOFVKp","executionInfo":{"status":"ok","timestamp":1601842156449,"user_tz":240,"elapsed":2822,"user":{"displayName":"Spencer Hoffman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKsq1sDpOiHSP5_-g5HIG4jyq-Cm0H11FItTDA=s64","userId":"10955597740158350437"}},"outputId":"ec26c091-e209-4727-aa2b-8a09a209f647","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["X = d2l.reshape(torch.arange(10), (2, 5))\n","F.one_hot(X.T, 28).shape"],"execution_count":477,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([5, 2, 28])"]},"metadata":{"tags":[]},"execution_count":477}]},{"cell_type":"markdown","metadata":{"origin_pos":14,"id":"I_LS0mmdFVKt"},"source":["## Initializing the Model Parameters\n","\n","Next, we initialize the model parameters for\n","the RNN model.\n","The number of hidden units `num_hiddens` is a tunable hyperparameter.\n","When training language models,\n","the inputs and outputs are from the same vocabulary.\n","Hence, they have the same dimension,\n","which is equal to the vocabulary size.\n"]},{"cell_type":"code","metadata":{"origin_pos":16,"tab":["pytorch"],"id":"kbXUA3MjFVKt","executionInfo":{"status":"ok","timestamp":1601842156450,"user_tz":240,"elapsed":2815,"user":{"displayName":"Spencer Hoffman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKsq1sDpOiHSP5_-g5HIG4jyq-Cm0H11FItTDA=s64","userId":"10955597740158350437"}}},"source":["def get_params(vocab_size, num_hiddens, device):\n","    num_inputs = num_outputs = vocab_size\n","\n","    def normal(shape):\n","        return torch.randn(size=shape, device=device) * 0.01\n","\n","    # Hidden layer parameters\n","    W_xh = normal((num_inputs, num_hiddens))\n","    W_hh = normal((num_hiddens, num_hiddens))\n","    b_h = torch.zeros(num_hiddens, device=device)\n","    # Output layer parameters\n","    W_hq = normal((num_hiddens, num_outputs))\n","    b_q = torch.zeros(num_outputs, device=device)\n","    # Attach gradients\n","    params = [W_xh, W_hh, b_h, W_hq, b_q]\n","    for param in params:\n","        param.requires_grad_(True)\n","    return params"],"execution_count":478,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":18,"id":"QLF1U-0ZFVKw"},"source":["## RNN Model\n","\n","To define an RNN model,\n","we first need an `init_rnn_state` function\n","to return the hidden state at initialization.\n","It returns a tensor filled with 0 and with a shape of (batch size, number of hidden units).\n","Using tuples makes it easier to handle situations where the hidden state contains multiple variables,\n","which we will encounter in later sections.\n"]},{"cell_type":"code","metadata":{"origin_pos":20,"tab":["pytorch"],"id":"r2JobOxlFVKw","executionInfo":{"status":"ok","timestamp":1601842156451,"user_tz":240,"elapsed":2813,"user":{"displayName":"Spencer Hoffman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKsq1sDpOiHSP5_-g5HIG4jyq-Cm0H11FItTDA=s64","userId":"10955597740158350437"}}},"source":["def init_rnn_state(batch_size, num_hiddens, device):\n","    return (torch.zeros((batch_size, num_hiddens), device=device), )"],"execution_count":479,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":22,"id":"334XPdvLFVKz"},"source":["The following `rnn` function defines how to compute the hidden state and output\n","at a time step.\n","Note that\n","the RNN model\n","loops through the outermost dimension of `inputs`\n","so that it updates hidden states `H` of a minibatch,\n","time step by time step.\n","Besides,\n","the activation function here uses the $\\tanh$ function.\n","As\n","described in :numref:`sec_mlp`, the\n","mean value of the $\\tanh$ function is 0, when the elements are uniformly\n","distributed over the real numbers.\n"]},{"cell_type":"code","metadata":{"origin_pos":24,"tab":["pytorch"],"id":"Zi_6a-L_FVK0","executionInfo":{"status":"ok","timestamp":1601842156451,"user_tz":240,"elapsed":2810,"user":{"displayName":"Spencer Hoffman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKsq1sDpOiHSP5_-g5HIG4jyq-Cm0H11FItTDA=s64","userId":"10955597740158350437"}}},"source":["def rnn(inputs, state, params):\n","    # Here `inputs` shape: (`num_steps`, `batch_size`, `vocab_size`)\n","    W_xh, W_hh, b_h, W_hq, b_q = params\n","    H, = state\n","    outputs = []\n","    # Shape of `X`: (`batch_size`, `vocab_size`)\n","    for X in inputs:\n","        H = torch.tanh(torch.mm(X, W_xh) + torch.mm(H, W_hh) + b_h)\n","        Y = torch.mm(H, W_hq) + b_q\n","        outputs.append(Y)\n","    return torch.cat(outputs, dim=0), (H,)"],"execution_count":480,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":26,"id":"YmkVDeqYFVK2"},"source":["With all the needed functions being defined,\n","next we create a class to wrap these functions and store parameters for an RNN model implemented from scratch.\n"]},{"cell_type":"code","metadata":{"origin_pos":28,"tab":["pytorch"],"id":"uvpgp6r3FVK2","executionInfo":{"status":"ok","timestamp":1601842156678,"user_tz":240,"elapsed":3034,"user":{"displayName":"Spencer Hoffman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKsq1sDpOiHSP5_-g5HIG4jyq-Cm0H11FItTDA=s64","userId":"10955597740158350437"}}},"source":["class RNNModelScratch: #@save\n","    \"\"\"A RNN Model implemented from scratch.\"\"\"\n","    def __init__(self, vocab_size, num_hiddens, device,\n","                 get_params, init_state, forward_fn):\n","        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens\n","        self.params = get_params(vocab_size, num_hiddens, device)\n","        self.init_state, self.forward_fn = init_state, forward_fn\n","\n","    def __call__(self, X, state):\n","        X = F.one_hot(X.T, self.vocab_size).type(torch.float32)\n","        return self.forward_fn(X, state, self.params)\n","\n","    def begin_state(self, batch_size, device):\n","        return self.init_state(batch_size, self.num_hiddens, device)"],"execution_count":481,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":30,"id":"Tl7gVuRUFVK5"},"source":["Let us check whether the outputs have the correct shapes, e.g., to ensure that the dimensionality of the hidden state remains unchanged.\n"]},{"cell_type":"code","metadata":{"origin_pos":32,"tab":["pytorch"],"id":"m1h7Sg-LFVK5","executionInfo":{"status":"ok","timestamp":1601842156679,"user_tz":240,"elapsed":3029,"user":{"displayName":"Spencer Hoffman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKsq1sDpOiHSP5_-g5HIG4jyq-Cm0H11FItTDA=s64","userId":"10955597740158350437"}},"outputId":"9bbac4ec-98b7-4e32-aa02-a7e814e748e3","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["num_hiddens = 512\n","model = RNNModelScratch(len(vocab), num_hiddens, d2l.try_gpu(), get_params,\n","                        init_rnn_state, rnn)\n","state = model.begin_state(X.shape[0], d2l.try_gpu())\n","Y, new_state = model(X.to(d2l.try_gpu()), state)\n","Y.shape, len(new_state), new_state[0].shape"],"execution_count":482,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([10, 28]), 1, torch.Size([2, 512]))"]},"metadata":{"tags":[]},"execution_count":482}]},{"cell_type":"markdown","metadata":{"origin_pos":34,"id":"hpnBWAwUFVK7"},"source":["We can see that the output shape is (number of time steps $\\times$ batch size, vocabulary size), while the hidden state shape remains the same, i.e., (batch size, number of hidden units).\n","\n","\n","## Prediction\n","\n","Let us first define the prediction function\n","to generate new characters following\n","the user-provided `prefix`,\n","which is a string containing several characters.\n","When looping through these beginning characters in `prefix`,\n","we keep passing the hidden state\n","to the next time step without\n","generating any output.\n","This is called the *warm-up* period,\n","during which the model updates itself\n","(e.g., update the hidden state)\n","but does not make predictions.\n","After the warm-up period,\n","the hidden state is generally better than\n","its initialized value at the beginning.\n","So we generate the predicted characters and emit them.\n"]},{"cell_type":"code","metadata":{"origin_pos":36,"tab":["pytorch"],"id":"aeRQtx7gFVK8","executionInfo":{"status":"ok","timestamp":1601842156679,"user_tz":240,"elapsed":3021,"user":{"displayName":"Spencer Hoffman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKsq1sDpOiHSP5_-g5HIG4jyq-Cm0H11FItTDA=s64","userId":"10955597740158350437"}},"outputId":"61b06358-e0b8-4c76-9e72-723130324308","colab":{"base_uri":"https://localhost:8080/","height":37}},"source":["def predict_ch8(prefix, num_preds, model, vocab, chooseCommon, chooseProbability, device):  #@save\n","    \"\"\"Generate new characters following the `prefix`.\"\"\"\n","    state = model.begin_state(batch_size=1, device=device)\n","    outputs = [vocab[prefix[0]]]\n","    get_input = lambda: d2l.reshape(torch.tensor(\n","        [outputs[-1]], device=device), (1, 1))\n","    for y in prefix[1:]:  # Warm-up period\n","        _, state = model(get_input(), state)\n","        outputs.append(vocab[y])\n","    for _ in range(num_preds):  # Predict `num_preds` steps\n","        y, state = model(get_input(), state)\n","\n","        y = F.softmax(y/0.25, dim=1)\n","\n","        # The following sections were testing various methods of selection (none worked well)\n","        if chooseCommon:\n","            h1 = int(y.argmax(dim=1).reshape(1))\n","            y_red = torch.cat([y[0][:h1], y[0][h1+1:]]).reshape(1,27)\n","            h2 = int(y_red.argmax(dim=1).reshape(1))\n","            if h1 <= h2:\n","                h2 += 1\n","            greater = vocab.token_freqs[h1-1][1] > vocab.token_freqs[h2-1][1]\n","            if chooseProbability:\n","                greater = math.log(vocab.token_freqs[h1-1][1])*y[0][h1] > math.log(vocab.token_freqs[h2-1][1])*y[0][h2]\n","            if greater:\n","                outputs.append(int(h1))\n","            else:\n","                outputs.append(int(h2))\n","        elif chooseProbability:\n","            y_freq = torch.zeros(1,28)\n","            for i in range(int(y.numel())-1):\n","                v_tok = math.log(vocab.token_freqs[i][1])\n","                y_tok = y[0][i].item()\n","                y_freq[0][i] = y_tok*v_tok\n","            outputs.append(int(y_freq.argmax(dim=1).reshape(1)))\n","        else:\n","            outputs.append(int(y.argmax(dim=1).reshape(1)))\n","    return ''.join([vocab.idx_to_token[i] for i in outputs])\n","predict_ch8('time traveller ', 1, model, vocab, False, False, d2l.try_gpu())"],"execution_count":483,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'time traveller e'"]},"metadata":{"tags":[]},"execution_count":483}]},{"cell_type":"markdown","metadata":{"origin_pos":38,"id":"_RrmMIGwFVK-"},"source":["Now we can test the `predict_ch8` function.\n","We specify the prefix as `time traveller ` and have it generate 10 additional characters.\n","Given that we have not trained the network,\n","it will generate nonsensical predictions.\n"]},{"cell_type":"code","metadata":{"origin_pos":39,"tab":["pytorch"],"id":"NfkY4keNFVK-","executionInfo":{"status":"ok","timestamp":1601842156680,"user_tz":240,"elapsed":3013,"user":{"displayName":"Spencer Hoffman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKsq1sDpOiHSP5_-g5HIG4jyq-Cm0H11FItTDA=s64","userId":"10955597740158350437"}},"outputId":"1d0ae11c-27f4-4a22-fb08-388900d59795","colab":{"base_uri":"https://localhost:8080/","height":37}},"source":["predict_ch8('time traveller ', 10, model, vocab, False, False, d2l.try_gpu())"],"execution_count":484,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'time traveller e e e e e '"]},"metadata":{"tags":[]},"execution_count":484}]},{"cell_type":"markdown","metadata":{"origin_pos":41,"id":"U-QrAj3qFVLB"},"source":["## Gradient Clipping\n","\n","For a sequence of length $T$,\n","we compute the gradients over these $T$ time steps in an iteration, which results in a chain of matrix-products with length  $\\mathcal{O}(T)$ during backpropagation.\n","As mentioned in :numref:`sec_numerical_stability`, it might result in numerical instability, e.g., the gradients may either explode or vanish, when $T$ is large. Therefore, RNN models often need extra help to stabilize the training.\n","\n","Generally speaking,\n","when solving an optimization problem,\n","we take update steps for the model parameter,\n","say in the vector form\n","$\\mathbf{x}$,\n","in the direction of the negative gradient $\\mathbf{g}$ on a minibatch.\n","For example,\n","with $\\eta > 0$ as the learning rate,\n","in one iteration we update\n","$\\mathbf{x}$\n","as $\\mathbf{x} - \\eta \\mathbf{g}$.\n","Let us further assume that the objective function $f$\n","is well behaved, say, *Lipschitz continuous* with constant $L$.\n","That is to say,\n","for any $\\mathbf{x}$ and $\\mathbf{y}$ we have\n","\n","$$|f(\\mathbf{x}) - f(\\mathbf{y})| \\leq L \\|\\mathbf{x} - \\mathbf{y}\\|.$$\n","\n","In this case we can safely assume that if we update the parameter vector by $\\eta \\mathbf{g}$, then\n","\n","$$|f(\\mathbf{x}) - f(\\mathbf{x} - \\eta\\mathbf{g})| \\leq L \\eta\\|\\mathbf{g}\\|,$$\n","\n","which means that\n","we will not observe a change by more than $L \\eta \\|\\mathbf{g}\\|$. This is both a curse and a blessing.\n","On the curse side,\n","it limits the speed of making progress;\n","whereas on the blessing side,\n","it limits the extent to which things can go wrong if we move in the wrong direction.\n","\n","Sometimes the gradients can be quite large and the optimization algorithm may fail to converge. We could address this by reducing the learning rate $\\eta$. But what if we only *rarely* get large gradients? In this case such an approach may appear entirely unwarranted. One popular alternative is to clip the gradient $\\mathbf{g}$ by projecting them back to a ball of a given radius, say $\\theta$ via\n","\n","$$\\mathbf{g} \\leftarrow \\min\\left(1, \\frac{\\theta}{\\|\\mathbf{g}\\|}\\right) \\mathbf{g}.$$\n","\n","By doing so we know that the gradient norm never exceeds $\\theta$ and that the\n","updated gradient is entirely aligned with the original direction of $\\mathbf{g}$.\n","It also has the desirable side-effect of limiting the influence any given\n","minibatch (and within it any given sample) can exert on the parameter vector. This\n","bestows a certain degree of robustness to the model. Gradient clipping provides\n","a quick fix to the gradient exploding. While it does not entirely solve the problem, it is one of the many techniques to alleviate it.\n","\n","Below we define a function to clip the gradients of\n","a model that is implemented from scratch or a model constructed by the high-level APIs.\n","Also note that we compute the gradient norm over all the model parameters.\n"]},{"cell_type":"code","metadata":{"origin_pos":43,"tab":["pytorch"],"id":"K6831h_YFVLB","executionInfo":{"status":"ok","timestamp":1601842156680,"user_tz":240,"elapsed":3005,"user":{"displayName":"Spencer Hoffman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKsq1sDpOiHSP5_-g5HIG4jyq-Cm0H11FItTDA=s64","userId":"10955597740158350437"}}},"source":["def grad_clipping(model, theta):  #@save\n","    \"\"\"Clip the gradient.\"\"\"\n","    if isinstance(model, nn.Module):\n","        params = [p for p in model.parameters() if p.requires_grad]\n","    else:\n","        params = model.params\n","    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n","    if norm > theta:\n","        for param in params:\n","            param.grad[:] *= theta / norm"],"execution_count":485,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":45,"id":"18qRvsl_FVLD"},"source":["## Training\n","\n","Before training the model,\n","let us define a function to train the model in one epoch. It differs from how we train the model of :numref:`sec_softmax_scratch` in three places:\n","\n","1. Different sampling methods for sequential data (random sampling and sequential partitioning) will result in differences in the initialization of hidden states.\n","1. We clip the gradients before updating the model parameters. This ensures that the model does not diverge even when gradients blow up at some point during the training process.\n","1. We use perplexity to evaluate the model. As discussed in :label:`subsec_perplexity`, this ensures that sequences of different length are comparable.\n","\n","\n","Specifically,\n","when sequential partitioning is used, we initialize the hidden state only at the beginning of each epoch.\n","Since the $i^\\mathrm{th}$ subsequence example  in the next minibatch is adjacent to the current $i^\\mathrm{th}$ subsequence example,\n","the hidden state at the end of the current minibatch\n","will be\n","used to initialize\n","the hidden state at the beginning of the next minibatch.\n","In this way,\n","historical information of the sequence\n","stored in the hidden state\n","might flow over\n","adjacent subsequences within an epoch.\n","However, the computation of the hidden state\n","at any point depends on all the previous minibatches\n","in the same epoch,\n","which complicates the gradient computation.\n","To reduce computational cost,\n","we detach the gradient before processing any minibatch\n","so that the gradient computation of the hidden state\n","is always limited to\n","the time steps in one minibatch. \n","\n","When using the random sampling,\n","we need to re-initialize the hidden state for each iteration since each example is sampled with a random position.\n","Same as the `train_epoch_ch3` function in :numref:`sec_softmax_scratch`,\n","`updater` is a general function\n","to update the model parameters.\n","It can be either the `d2l.sgd` function implemented from scratch or the built-in optimization function in\n","a deep learning framework.\n"]},{"cell_type":"code","metadata":{"origin_pos":47,"tab":["pytorch"],"id":"BBypPfdwFVLD","executionInfo":{"status":"ok","timestamp":1601842156681,"user_tz":240,"elapsed":3003,"user":{"displayName":"Spencer Hoffman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKsq1sDpOiHSP5_-g5HIG4jyq-Cm0H11FItTDA=s64","userId":"10955597740158350437"}}},"source":["def train_epoch_ch8(model, train_iter, loss, updater, device,  #@save\n","                    use_random_iter):\n","    \"\"\"Train a model within one epoch (defined in Chapter 8).\"\"\"\n","    state, timer = None, d2l.Timer()\n","    metric = d2l.Accumulator(2)  # Sum of training loss, no. of tokens\n","    for X, Y in train_iter:\n","        if state is None or use_random_iter:\n","            # Initialize `state` when either it is the first iteration or\n","            # using random sampling\n","            state = model.begin_state(batch_size=X.shape[0], device=device)\n","        else:\n","            if isinstance(model, nn.Module) and not isinstance(state, tuple):\n","                # `state` is a tensor for `nn.GRU`\n","                state.detach_()\n","            else:\n","                # `state` is a tuple of tensors for `nn.LSTM` and\n","                # for our custom scratch implementation \n","                for s in state:\n","                    s.detach_()\n","        y = Y.T.reshape(-1)\n","        X, y = X.to(device), y.to(device)\n","        y_hat, state = model(X, state)\n","        l = loss(y_hat, y.long()).mean()\n","        if isinstance(updater, torch.optim.Optimizer):\n","            updater.zero_grad()\n","            l.backward()\n","            grad_clipping(model, 1)\n","            updater.step()\n","        else:\n","            l.backward()\n","            grad_clipping(model, 1)\n","            # Since the `mean` function has been invoked\n","            updater(batch_size=1)\n","        metric.add(l * d2l.size(y), d2l.size(y))\n","    return math.exp(metric[0] / metric[1]), metric[1] / timer.stop()"],"execution_count":486,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":49,"id":"iTRLHmGmFVLF"},"source":["The training function supports\n","an RNN model implemented\n","either from scratch\n","or using high-level APIs.\n"]},{"cell_type":"code","metadata":{"origin_pos":51,"tab":["pytorch"],"id":"o2T8EHgsFVLF","executionInfo":{"status":"ok","timestamp":1601842156681,"user_tz":240,"elapsed":3000,"user":{"displayName":"Spencer Hoffman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKsq1sDpOiHSP5_-g5HIG4jyq-Cm0H11FItTDA=s64","userId":"10955597740158350437"}}},"source":["#@save\n","def train_ch8(model, train_iter, vocab, lr, num_epochs, device,\n","              use_random_iter=False):\n","    \"\"\"Train a model (defined in Chapter 8).\"\"\"\n","    loss = nn.CrossEntropyLoss()\n","    animator = d2l.Animator(xlabel='epoch', ylabel='perplexity',\n","                            legend=['train'], xlim=[1, num_epochs])\n","    # Initialize\n","    if isinstance(model, nn.Module):\n","        updater = torch.optim.SGD(model.parameters(), lr)\n","    else:\n","        updater = lambda batch_size: d2l.sgd(model.params, lr, batch_size)\n","    predict = lambda prefix: predict_ch8(prefix, 50, model, vocab, False, False, device)\n","    # Train and predict\n","    for epoch in range(num_epochs):\n","        ppl, speed = train_epoch_ch8(\n","            model, train_iter, loss, updater, device, use_random_iter)\n","        if epoch % 10 == 0:\n","            print(predict('time traveller'))\n","            animator.add(epoch + 1, [ppl])\n","    print(f'perplexity {ppl:.1f}, {speed:.1f} tokens/sec on {str(device)}')\n","    print(predict('time traveller'))\n","    print(predict('traveller'))\n","    print(predict('filby'))"],"execution_count":487,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":53,"id":"c8OwjGMoFVLH"},"source":["Now we can train the RNN model.\n","Since we only use 10000 tokens in the dataset, the model needs more epochs to converge better.\n"]},{"cell_type":"code","metadata":{"origin_pos":54,"tab":["pytorch"],"id":"5mCwGUDdFVLI","executionInfo":{"status":"ok","timestamp":1601842219569,"user_tz":240,"elapsed":65885,"user":{"displayName":"Spencer Hoffman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKsq1sDpOiHSP5_-g5HIG4jyq-Cm0H11FItTDA=s64","userId":"10955597740158350437"}},"outputId":"f3e3185c-d771-403d-89b0-3002a62dfa0f","colab":{"base_uri":"https://localhost:8080/","height":329}},"source":["num_epochs, lr = 500, 1\n","train_ch8(model, train_iter, vocab, lr, num_epochs, d2l.try_gpu())"],"execution_count":488,"outputs":[{"output_type":"stream","text":["perplexity 1.0, 87082.9 tokens/sec on cuda:0\n","time traveller for so it will be convenient to speak of himwas e\n","travelleryou can show black is white by argument said filby\n","filby thing to expect us to begin uponsaid filby an arg\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/plain":["<Figure size 252x180 with 1 Axes>"],"image/svg+xml":"<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"180.65625pt\" version=\"1.1\" viewBox=\"0 0 252.646875 180.65625\" width=\"252.646875pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 180.65625 \nL 252.646875 180.65625 \nL 252.646875 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 40.603125 143.1 \nL 235.903125 143.1 \nL 235.903125 7.2 \nL 40.603125 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#p65ccd018a4)\" d=\"M 79.350019 143.1 \nL 79.350019 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"mc7329cb346\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"79.350019\" xlink:href=\"#mc7329cb346\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 100 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(69.806269 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#p65ccd018a4)\" d=\"M 118.488295 143.1 \nL 118.488295 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"118.488295\" xlink:href=\"#mc7329cb346\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 200 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(108.944545 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#p65ccd018a4)\" d=\"M 157.626572 143.1 \nL 157.626572 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"157.626572\" xlink:href=\"#mc7329cb346\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 300 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(148.082822 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#p65ccd018a4)\" d=\"M 196.764848 143.1 \nL 196.764848 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"196.764848\" xlink:href=\"#mc7329cb346\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 400 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(187.221098 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#p65ccd018a4)\" d=\"M 235.903125 143.1 \nL 235.903125 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"235.903125\" xlink:href=\"#mc7329cb346\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 500 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(226.359375 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_6\">\n     <!-- epoch -->\n     <defs>\n      <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n      <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n      <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n      <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-104\"/>\n     </defs>\n     <g transform=\"translate(123.025 171.376563)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"61.523438\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"125\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"186.181641\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"241.162109\" xlink:href=\"#DejaVuSans-104\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#p65ccd018a4)\" d=\"M 40.603125 142.264755 \nL 235.903125 142.264755 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m947f5a4646\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#m947f5a4646\" y=\"142.264755\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0 -->\n      <g transform=\"translate(27.240625 146.063974)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_13\">\n      <path clip-path=\"url(#p65ccd018a4)\" d=\"M 40.603125 116.227947 \nL 235.903125 116.227947 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#m947f5a4646\" y=\"116.227947\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 5 -->\n      <g transform=\"translate(27.240625 120.027166)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_15\">\n      <path clip-path=\"url(#p65ccd018a4)\" d=\"M 40.603125 90.191139 \nL 235.903125 90.191139 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#m947f5a4646\" y=\"90.191139\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 10 -->\n      <g transform=\"translate(20.878125 93.990358)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_17\">\n      <path clip-path=\"url(#p65ccd018a4)\" d=\"M 40.603125 64.154331 \nL 235.903125 64.154331 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#m947f5a4646\" y=\"64.154331\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 15 -->\n      <g transform=\"translate(20.878125 67.95355)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_19\">\n      <path clip-path=\"url(#p65ccd018a4)\" d=\"M 40.603125 38.117523 \nL 235.903125 38.117523 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_20\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#m947f5a4646\" y=\"38.117523\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 20 -->\n      <g transform=\"translate(20.878125 41.916741)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_21\">\n      <path clip-path=\"url(#p65ccd018a4)\" d=\"M 40.603125 12.080715 \nL 235.903125 12.080715 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_22\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#m947f5a4646\" y=\"12.080715\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 25 -->\n      <g transform=\"translate(20.878125 15.879933)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_13\">\n     <!-- perplexity -->\n     <defs>\n      <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n      <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n      <path d=\"M 54.890625 54.6875 \nL 35.109375 28.078125 \nL 55.90625 0 \nL 45.3125 0 \nL 29.390625 21.484375 \nL 13.484375 0 \nL 2.875 0 \nL 24.125 28.609375 \nL 4.6875 54.6875 \nL 15.28125 54.6875 \nL 29.78125 35.203125 \nL 44.28125 54.6875 \nz\n\" id=\"DejaVuSans-120\"/>\n      <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n      <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n      <path d=\"M 32.171875 -5.078125 \nQ 28.375 -14.84375 24.75 -17.8125 \nQ 21.140625 -20.796875 15.09375 -20.796875 \nL 7.90625 -20.796875 \nL 7.90625 -13.28125 \nL 13.1875 -13.28125 \nQ 16.890625 -13.28125 18.9375 -11.515625 \nQ 21 -9.765625 23.484375 -3.21875 \nL 25.09375 0.875 \nL 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 11.921875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nz\n\" id=\"DejaVuSans-121\"/>\n     </defs>\n     <g transform=\"translate(14.798437 100.276562)rotate(-90)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"63.476562\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"125\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"166.113281\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"229.589844\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"257.373047\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"317.146484\" xlink:href=\"#DejaVuSans-120\"/>\n      <use x=\"376.326172\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"404.109375\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"443.318359\" xlink:href=\"#DejaVuSans-121\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_23\">\n    <path clip-path=\"url(#p65ccd018a4)\" d=\"M 40.603125 13.377273 \nL 44.516953 75.066261 \nL 48.43078 87.95876 \nL 52.344608 92.630578 \nL 56.258436 95.747359 \nL 60.172263 97.861805 \nL 64.086091 99.47827 \nL 67.999919 100.795636 \nL 71.913746 101.796491 \nL 75.827574 102.965354 \nL 79.741402 104.167846 \nL 83.655229 105.821539 \nL 87.569057 106.458527 \nL 91.482885 109.147692 \nL 95.396712 110.299233 \nL 99.31054 112.256662 \nL 103.224367 115.157249 \nL 107.138195 118.622958 \nL 111.052023 122.112176 \nL 114.96585 124.530924 \nL 118.879678 127.151167 \nL 122.793506 129.081454 \nL 126.707333 130.879043 \nL 130.621161 131.976085 \nL 134.534989 133.704242 \nL 138.448816 134.21295 \nL 142.362644 134.711542 \nL 146.276472 135.000305 \nL 150.190299 135.12974 \nL 154.104127 135.592335 \nL 158.017955 135.681375 \nL 161.931782 135.972717 \nL 165.84561 136.239261 \nL 169.759438 136.656096 \nL 173.673265 136.659189 \nL 177.587093 136.46517 \nL 181.500921 136.652128 \nL 185.414748 136.800511 \nL 189.328576 136.797968 \nL 193.242404 136.350753 \nL 197.156231 135.883113 \nL 201.070059 136.087526 \nL 204.983887 136.194976 \nL 208.897714 136.487755 \nL 212.811542 136.735985 \nL 216.725369 136.679238 \nL 220.639197 136.922727 \nL 224.553025 136.881022 \nL 228.466852 136.827576 \nL 232.38068 136.806156 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 40.603125 143.1 \nL 40.603125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 235.903125 143.1 \nL 235.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 40.603125 143.1 \nL 235.903125 143.1 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 40.603125 7.2 \nL 235.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 173.628125 29.878125 \nL 228.903125 29.878125 \nQ 230.903125 29.878125 230.903125 27.878125 \nL 230.903125 14.2 \nQ 230.903125 12.2 228.903125 12.2 \nL 173.628125 12.2 \nQ 171.628125 12.2 171.628125 14.2 \nL 171.628125 27.878125 \nQ 171.628125 29.878125 173.628125 29.878125 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_24\">\n     <path d=\"M 175.628125 20.298437 \nL 195.628125 20.298437 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_25\"/>\n    <g id=\"text_14\">\n     <!-- train -->\n     <defs>\n      <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n     </defs>\n     <g transform=\"translate(203.628125 23.798437)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p65ccd018a4\">\n   <rect height=\"135.9\" width=\"195.3\" x=\"40.603125\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n"},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"origin_pos":56,"id":"77Fo1adgFVLK"},"source":["Finally,\n","let us check the results of using the random sampling method.\n"]},{"cell_type":"code","metadata":{"origin_pos":57,"tab":["pytorch"],"id":"6ms7RFkuFVLK","executionInfo":{"status":"ok","timestamp":1601842282042,"user_tz":240,"elapsed":128349,"user":{"displayName":"Spencer Hoffman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKsq1sDpOiHSP5_-g5HIG4jyq-Cm0H11FItTDA=s64","userId":"10955597740158350437"}},"outputId":"f7b097bd-e5a6-40f0-a9f0-3f72ca8f8c71","colab":{"base_uri":"https://localhost:8080/","height":329}},"source":["train_ch8(model, train_iter, vocab, lr, num_epochs, d2l.try_gpu(),\n","          use_random_iter=True)"],"execution_count":489,"outputs":[{"output_type":"stream","text":["perplexity 1.4, 80852.0 tokens/sec on cuda:0\n","time travellerit s against reason said filbywhat is you siok ong\n","travellerit s against reason said filbywhat is you siok ong\n","filby became pensive clearly the time traveller proceed\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/plain":["<Figure size 252x180 with 1 Axes>"],"image/svg+xml":"<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"180.65625pt\" version=\"1.1\" viewBox=\"0 0 255.825 180.65625\" width=\"255.825pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 180.65625 \nL 255.825 180.65625 \nL 255.825 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 43.78125 143.1 \nL 239.08125 143.1 \nL 239.08125 7.2 \nL 43.78125 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#p1bae404c1a)\" d=\"M 82.528144 143.1 \nL 82.528144 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m6366781c85\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"82.528144\" xlink:href=\"#m6366781c85\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 100 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(72.984394 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#p1bae404c1a)\" d=\"M 121.66642 143.1 \nL 121.66642 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"121.66642\" xlink:href=\"#m6366781c85\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 200 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(112.12267 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#p1bae404c1a)\" d=\"M 160.804697 143.1 \nL 160.804697 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"160.804697\" xlink:href=\"#m6366781c85\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 300 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(151.260947 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#p1bae404c1a)\" d=\"M 199.942973 143.1 \nL 199.942973 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"199.942973\" xlink:href=\"#m6366781c85\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 400 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(190.399223 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#p1bae404c1a)\" d=\"M 239.08125 143.1 \nL 239.08125 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"239.08125\" xlink:href=\"#m6366781c85\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 500 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(229.5375 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_6\">\n     <!-- epoch -->\n     <defs>\n      <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n      <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n      <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n      <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-104\"/>\n     </defs>\n     <g transform=\"translate(126.203125 171.376563)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"61.523438\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"125\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"186.181641\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"241.162109\" xlink:href=\"#DejaVuSans-104\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#p1bae404c1a)\" d=\"M 43.78125 139.39225 \nL 239.08125 139.39225 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m7b985b6893\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m7b985b6893\" y=\"139.39225\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 1.2 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(20.878125 143.191469)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_13\">\n      <path clip-path=\"url(#p1bae404c1a)\" d=\"M 43.78125 115.14367 \nL 239.08125 115.14367 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m7b985b6893\" y=\"115.14367\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 1.4 -->\n      <g transform=\"translate(20.878125 118.942889)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_15\">\n      <path clip-path=\"url(#p1bae404c1a)\" d=\"M 43.78125 90.895089 \nL 239.08125 90.895089 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m7b985b6893\" y=\"90.895089\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 1.6 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(20.878125 94.694308)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_17\">\n      <path clip-path=\"url(#p1bae404c1a)\" d=\"M 43.78125 66.646509 \nL 239.08125 66.646509 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m7b985b6893\" y=\"66.646509\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 1.8 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(20.878125 70.445727)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_19\">\n      <path clip-path=\"url(#p1bae404c1a)\" d=\"M 43.78125 42.397928 \nL 239.08125 42.397928 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_20\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m7b985b6893\" y=\"42.397928\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 2.0 -->\n      <g transform=\"translate(20.878125 46.197147)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_21\">\n      <path clip-path=\"url(#p1bae404c1a)\" d=\"M 43.78125 18.149348 \nL 239.08125 18.149348 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_22\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m7b985b6893\" y=\"18.149348\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 2.2 -->\n      <g transform=\"translate(20.878125 21.948566)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_13\">\n     <!-- perplexity -->\n     <defs>\n      <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n      <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n      <path d=\"M 54.890625 54.6875 \nL 35.109375 28.078125 \nL 55.90625 0 \nL 45.3125 0 \nL 29.390625 21.484375 \nL 13.484375 0 \nL 2.875 0 \nL 24.125 28.609375 \nL 4.6875 54.6875 \nL 15.28125 54.6875 \nL 29.78125 35.203125 \nL 44.28125 54.6875 \nz\n\" id=\"DejaVuSans-120\"/>\n      <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n      <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n      <path d=\"M 32.171875 -5.078125 \nQ 28.375 -14.84375 24.75 -17.8125 \nQ 21.140625 -20.796875 15.09375 -20.796875 \nL 7.90625 -20.796875 \nL 7.90625 -13.28125 \nL 13.1875 -13.28125 \nQ 16.890625 -13.28125 18.9375 -11.515625 \nQ 21 -9.765625 23.484375 -3.21875 \nL 25.09375 0.875 \nL 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 11.921875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nz\n\" id=\"DejaVuSans-121\"/>\n     </defs>\n     <g transform=\"translate(14.798438 100.276562)rotate(-90)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"63.476562\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"125\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"166.113281\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"229.589844\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"257.373047\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"317.146484\" xlink:href=\"#DejaVuSans-120\"/>\n      <use x=\"376.326172\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"404.109375\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"443.318359\" xlink:href=\"#DejaVuSans-121\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_23\">\n    <path clip-path=\"url(#p1bae404c1a)\" d=\"M 43.78125 13.377273 \nL 47.695078 29.861939 \nL 51.608905 57.429384 \nL 55.522733 61.645596 \nL 59.436561 83.821334 \nL 63.350388 74.803775 \nL 67.264216 85.372661 \nL 71.178044 85.819245 \nL 75.091871 95.564497 \nL 79.005699 87.485779 \nL 82.919527 100.617524 \nL 86.833354 93.390373 \nL 90.747182 110.450592 \nL 94.66101 105.766871 \nL 98.574837 102.151594 \nL 102.488665 112.452494 \nL 106.402492 129.922006 \nL 110.31632 124.693945 \nL 114.230148 105.915221 \nL 118.143975 115.413947 \nL 122.057803 123.84271 \nL 125.971631 121.171283 \nL 129.885458 119.499971 \nL 133.799286 119.03839 \nL 137.713114 119.988378 \nL 141.626941 119.872894 \nL 145.540769 111.59029 \nL 149.454597 105.016788 \nL 153.368424 115.926968 \nL 157.282252 117.682261 \nL 161.19608 117.239953 \nL 165.109907 126.345188 \nL 169.023735 125.765201 \nL 172.937563 119.950383 \nL 176.85139 123.773829 \nL 180.765218 118.336113 \nL 184.679046 118.739112 \nL 188.592873 122.371691 \nL 192.506701 134.692513 \nL 196.420529 118.716719 \nL 200.334356 119.125921 \nL 204.248184 125.537896 \nL 208.162012 129.507955 \nL 212.075839 127.000296 \nL 215.989667 126.53862 \nL 219.903494 117.748874 \nL 223.817322 136.922727 \nL 227.73115 126.877304 \nL 231.644977 122.423419 \nL 235.558805 120.487192 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 43.78125 143.1 \nL 43.78125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 239.08125 143.1 \nL 239.08125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 43.78125 143.1 \nL 239.08125 143.1 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 43.78125 7.2 \nL 239.08125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 176.80625 29.878125 \nL 232.08125 29.878125 \nQ 234.08125 29.878125 234.08125 27.878125 \nL 234.08125 14.2 \nQ 234.08125 12.2 232.08125 12.2 \nL 176.80625 12.2 \nQ 174.80625 12.2 174.80625 14.2 \nL 174.80625 27.878125 \nQ 174.80625 29.878125 176.80625 29.878125 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_24\">\n     <path d=\"M 178.80625 20.298437 \nL 198.80625 20.298437 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_25\"/>\n    <g id=\"text_14\">\n     <!-- train -->\n     <defs>\n      <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n     </defs>\n     <g transform=\"translate(206.80625 23.798437)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p1bae404c1a\">\n   <rect height=\"135.9\" width=\"195.3\" x=\"43.78125\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n"},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"origin_pos":59,"id":"E2i1nI5gFVLN"},"source":["While implementing the above RNN model from scratch is instructive, it is not convenient.\n","In the next section we will see how to improve the RNN model,\n","such as how to make it easier to implement\n","and make it run faster.\n","\n","\n","## Summary\n","\n","* We can train an RNN-based character-level language model to generate text following the user-provided text prefix.\n","* A simple RNN language model consists of input encoding, RNN modeling, and output generation.\n","* RNN models need state initialization for training, though random sampling and sequential partitioning use different ways.\n","* When using sequential partitioning, we need to detach the gradient to reduce computational cost.\n","* A warm-up period allows a model to update itself (e.g., obtain a better hidden state than its initialized value) before making any prediction.\n","* Gradient clipping prevents gradient explosion, but it cannot fix vanishing gradients.\n","\n","\n","## Exercises\n","\n","1. Show that one-hot encoding is equivalent to picking a different embedding for each object.\n","1. Adjust the hyperparameters (e.g., number of epochs, number of hidden units, number of time steps in a minibatch, and learning rate) to improve the perplexity.\n","    * How low can you go?\n","    * Replace random sampling with sequential partitioning. Does this lead to better performance?\n","    * Replace one-hot encoding with learnable embeddings. Does this lead to better performance?\n","    * How well will it work on other books by H. G. Wells, e.g., [*The War of the Worlds*](http://www.gutenberg.org/ebooks/36)?\n","1. Modify the prediction function such as to use sampling rather than picking the most likely next character.\n","    * What happens?\n","    * Bias the model towards more likely outputs, e.g., by sampling from $q(x_t \\mid x_{t-1}, \\ldots, x_1) \\propto P(x_t \\mid x_{t-1}, \\ldots, x_1)^\\alpha$ for $\\alpha > 1$.\n","1. Run the code in this section without clipping the gradient. What happens?\n","1. Change sequential partitioning so that it does not separate hidden states from the computational graph. Does the running time change? How about the perplexity?\n","1. Replace the activation function used in this section with ReLU and repeat the experiments in this section. Do we still need gradient clipping? Why?\n"]},{"cell_type":"markdown","metadata":{"origin_pos":61,"tab":["pytorch"],"id":"AK0WV3hRFVLN"},"source":["[Discussions](https://discuss.d2l.ai/t/486)\n"]}]}